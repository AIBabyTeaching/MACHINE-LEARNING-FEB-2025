{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "159d61e2",
   "metadata": {},
   "source": [
    "# Machine Learning - IN221 - February 2025\n",
    "## Eng. Ahmed Métwalli\n",
    "## Week 10 - Regularization! Tackling overfitting apart!\n",
    "\n",
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7631da63",
   "metadata": {},
   "source": [
    "In this lab, we are going to use another data (Classification of Covid)\n",
    "\n",
    "**Covid-19 Classification Data**\n",
    "\n",
    "Contains a vast number of anonymized patient-related information including pre-conditions. The raw dataset consists of 21 different features and 1,048,576 unique patients. In the Boolean features, 1 means \"yes\" and 2 means \"no\". values as 97 and 99 are missing data.\n",
    "\n",
    "Dataset Source: https://www.kaggle.com/datasets/meirnizri/covid19-dataset?resource=download\n",
    "\n",
    "**Attributes** :\n",
    " \n",
    "content\n",
    "The dataset was provided by the Mexican government (link). This dataset contains an enormous number of anonymized patient-related information including pre-conditions. The raw dataset consists of 21 unique features and 1,048,576 unique patients. In the Boolean features, 1 means \"yes\" and 2 means \"no\". values as 97 and 99 are missing data.\n",
    "\n",
    "- sex: 1 for female and 2 for male.\n",
    "- age: of the patient.\n",
    "- classification: covid test findings. Values 1-3 mean that the patient was diagnosed with covid in different degrees. 4 or higher means that the patient is not a carrier of covid or that the test is inconclusive.\n",
    "- patient type: type of care the patient received in the unit. 1 for returned home and 2 for hospitalization.\n",
    "- pneumonia: whether the patient already have air sacs inflammation or not.\n",
    "- pregnancy: whether the patient is pregnant or not.\n",
    "- diabetes: whether the patient has diabetes or not.\n",
    "- copd: Indicates whether the patient has Chronic obstructive pulmonary disease or not.\n",
    "- asthma: whether the patient has asthma or not.\n",
    "- inmsupr: whether the patient is immunosuppressed or not.\n",
    "- hypertension: whether the patient has hypertension or not.\n",
    "- cardiovascular: whether the patient has heart or blood vessels related disease.\n",
    "- renal chronic: whether the patient has chronic renal disease or not.\n",
    "- other disease: whether the patient has other disease or not.\n",
    "- obesity: whether the patient is obese or not.\n",
    "- tobacco: whether the patient is a tobacco user.\n",
    "- usmr: Indicates whether the patient treated medical units of the first, second or third level.\n",
    "- medical unit: type of institution of the National Health System that provided the care.\n",
    "- intubed: whether the patient was connected to the ventilator.\n",
    "- icu: Indicates whether the patient had been admitted to an Intensive Care Unit.\n",
    "- date died: If the patient died indicate the date of death, and 9999-99-99 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0f42e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count    Dtype \n",
      "---  ------                --------------    ----- \n",
      " 0   USMER                 1048575 non-null  int64 \n",
      " 1   MEDICAL_UNIT          1048575 non-null  int64 \n",
      " 2   SEX                   1048575 non-null  int64 \n",
      " 3   PATIENT_TYPE          1048575 non-null  int64 \n",
      " 4   DATE_DIED             1048575 non-null  object\n",
      " 5   INTUBED               1048575 non-null  int64 \n",
      " 6   PNEUMONIA             1048575 non-null  int64 \n",
      " 7   AGE                   1048575 non-null  int64 \n",
      " 8   PREGNANT              1048575 non-null  int64 \n",
      " 9   DIABETES              1048575 non-null  int64 \n",
      " 10  COPD                  1048575 non-null  int64 \n",
      " 11  ASTHMA                1048575 non-null  int64 \n",
      " 12  INMSUPR               1048575 non-null  int64 \n",
      " 13  HIPERTENSION          1048575 non-null  int64 \n",
      " 14  OTHER_DISEASE         1048575 non-null  int64 \n",
      " 15  CARDIOVASCULAR        1048575 non-null  int64 \n",
      " 16  OBESITY               1048575 non-null  int64 \n",
      " 17  RENAL_CHRONIC         1048575 non-null  int64 \n",
      " 18  TOBACCO               1048575 non-null  int64 \n",
      " 19  CLASIFFICATION_FINAL  1048575 non-null  int64 \n",
      " 20  ICU                   1048575 non-null  int64 \n",
      "dtypes: int64(20), object(1)\n",
      "memory usage: 168.0+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Public Datasets/classification_covid.zip',compression='zip')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cf5479",
   "metadata": {},
   "source": [
    "- No Actual Missing NaNs, but the missing data holding 97,98,99 as the documentation said!!\n",
    "- This is tricky!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1d2eec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "USMER",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MEDICAL_UNIT",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SEX",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PATIENT_TYPE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DATE_DIED",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "INTUBED",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PNEUMONIA",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "AGE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PREGNANT",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DIABETES",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "COPD",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ASTHMA",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "INMSUPR",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "HIPERTENSION",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OTHER_DISEASE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CARDIOVASCULAR",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "OBESITY",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "RENAL_CHRONIC",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TOBACCO",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CLASIFFICATION_FINAL",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ICU",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "20a00d44-3680-42d5-b804-2c201677ff93",
       "rows": [
        [
         "988319",
         "2",
         "12",
         "1",
         "1",
         "9999-99-99",
         "97",
         "2",
         "27",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "7",
         "97"
        ],
        [
         "1047029",
         "1",
         "12",
         "1",
         "1",
         "9999-99-99",
         "97",
         "2",
         "30",
         "2",
         "2",
         "2",
         "1",
         "2",
         "2",
         "2",
         "2",
         "1",
         "2",
         "2",
         "7",
         "97"
        ],
        [
         "452466",
         "1",
         "12",
         "2",
         "2",
         "23/05/2020",
         "2",
         "1",
         "74",
         "97",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "1",
         "2",
         "2",
         "3",
         "2"
        ],
        [
         "39112",
         "1",
         "4",
         "2",
         "2",
         "11/06/2020",
         "2",
         "1",
         "66",
         "97",
         "1",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "3",
         "2"
        ],
        [
         "702218",
         "1",
         "12",
         "1",
         "1",
         "9999-99-99",
         "97",
         "2",
         "46",
         "2",
         "1",
         "2",
         "2",
         "2",
         "1",
         "2",
         "2",
         "2",
         "2",
         "2",
         "6",
         "97"
        ],
        [
         "475308",
         "1",
         "12",
         "2",
         "1",
         "9999-99-99",
         "97",
         "2",
         "50",
         "97",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "3",
         "97"
        ],
        [
         "495467",
         "1",
         "12",
         "1",
         "1",
         "9999-99-99",
         "97",
         "2",
         "15",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "3",
         "97"
        ],
        [
         "145054",
         "2",
         "4",
         "2",
         "1",
         "9999-99-99",
         "97",
         "2",
         "30",
         "97",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "3",
         "97"
        ],
        [
         "424122",
         "1",
         "9",
         "1",
         "1",
         "9999-99-99",
         "97",
         "1",
         "43",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "7",
         "97"
        ],
        [
         "1031826",
         "2",
         "12",
         "1",
         "1",
         "9999-99-99",
         "97",
         "2",
         "34",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "2",
         "7",
         "97"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USMER</th>\n",
       "      <th>MEDICAL_UNIT</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PATIENT_TYPE</th>\n",
       "      <th>DATE_DIED</th>\n",
       "      <th>INTUBED</th>\n",
       "      <th>PNEUMONIA</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PREGNANT</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>...</th>\n",
       "      <th>ASTHMA</th>\n",
       "      <th>INMSUPR</th>\n",
       "      <th>HIPERTENSION</th>\n",
       "      <th>OTHER_DISEASE</th>\n",
       "      <th>CARDIOVASCULAR</th>\n",
       "      <th>OBESITY</th>\n",
       "      <th>RENAL_CHRONIC</th>\n",
       "      <th>TOBACCO</th>\n",
       "      <th>CLASIFFICATION_FINAL</th>\n",
       "      <th>ICU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>988319</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9999-99-99</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047029</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9999-99-99</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452466</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23/05/2020</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39112</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11/06/2020</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702218</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9999-99-99</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475308</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9999-99-99</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495467</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9999-99-99</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145054</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9999-99-99</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424122</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9999-99-99</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031826</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9999-99-99</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         USMER  MEDICAL_UNIT  SEX  PATIENT_TYPE   DATE_DIED  INTUBED  \\\n",
       "988319       2            12    1             1  9999-99-99       97   \n",
       "1047029      1            12    1             1  9999-99-99       97   \n",
       "452466       1            12    2             2  23/05/2020        2   \n",
       "39112        1             4    2             2  11/06/2020        2   \n",
       "702218       1            12    1             1  9999-99-99       97   \n",
       "475308       1            12    2             1  9999-99-99       97   \n",
       "495467       1            12    1             1  9999-99-99       97   \n",
       "145054       2             4    2             1  9999-99-99       97   \n",
       "424122       1             9    1             1  9999-99-99       97   \n",
       "1031826      2            12    1             1  9999-99-99       97   \n",
       "\n",
       "         PNEUMONIA  AGE  PREGNANT  DIABETES  ...  ASTHMA  INMSUPR  \\\n",
       "988319           2   27         2         2  ...       2        2   \n",
       "1047029          2   30         2         2  ...       1        2   \n",
       "452466           1   74        97         2  ...       2        2   \n",
       "39112            1   66        97         1  ...       2        2   \n",
       "702218           2   46         2         1  ...       2        2   \n",
       "475308           2   50        97         2  ...       2        2   \n",
       "495467           2   15         2         2  ...       2        2   \n",
       "145054           2   30        97         2  ...       2        2   \n",
       "424122           1   43         2         2  ...       2        2   \n",
       "1031826          2   34         2         2  ...       2        2   \n",
       "\n",
       "         HIPERTENSION  OTHER_DISEASE  CARDIOVASCULAR  OBESITY  RENAL_CHRONIC  \\\n",
       "988319              2              2               2        2              2   \n",
       "1047029             2              2               2        1              2   \n",
       "452466              2              2               2        1              2   \n",
       "39112               2              2               2        2              2   \n",
       "702218              1              2               2        2              2   \n",
       "475308              2              2               2        2              2   \n",
       "495467              2              2               2        2              2   \n",
       "145054              2              2               2        2              2   \n",
       "424122              2              2               2        2              2   \n",
       "1031826             2              2               2        2              2   \n",
       "\n",
       "         TOBACCO  CLASIFFICATION_FINAL  ICU  \n",
       "988319         2                     7   97  \n",
       "1047029        2                     7   97  \n",
       "452466         2                     3    2  \n",
       "39112          2                     3    2  \n",
       "702218         2                     6   97  \n",
       "475308         2                     3   97  \n",
       "495467         2                     3   97  \n",
       "145054         2                     3   97  \n",
       "424122         2                     7   97  \n",
       "1031826        2                     7   97  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c0d9fa",
   "metadata": {},
   "source": [
    "**Handling Missing Data**:\n",
    "- First, counting the proportion of missing data (the ones having 97,98,99 codes)\n",
    "- Second, look by manual inspection for the date died\n",
    "- Third, choose which feature to be dropped then.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6f29ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['USMER', 'MEDICAL_UNIT', 'SEX', 'PATIENT_TYPE', 'DATE_DIED', 'INTUBED',\n",
       "       'PNEUMONIA', 'AGE', 'PREGNANT', 'DIABETES', 'COPD', 'ASTHMA', 'INMSUPR',\n",
       "       'HIPERTENSION', 'OTHER_DISEASE', 'CARDIOVASCULAR', 'OBESITY',\n",
       "       'RENAL_CHRONIC', 'TOBACCO', 'CLASIFFICATION_FINAL', 'ICU'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf9c74c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'USMER': 0.0,\n",
       " 'MEDICAL_UNIT': 0.0,\n",
       " 'SEX': 0.0,\n",
       " 'PATIENT_TYPE': 0.0,\n",
       " 'DATE_DIED': 0.9266223207686622,\n",
       " 'INTUBED': 0.816221061917364,\n",
       " 'PNEUMONIA': 0.015261664640106812,\n",
       " 'AGE': 0.0003290179529361276,\n",
       " 'PREGNANT': 0.5028395679851226,\n",
       " 'DIABETES': 0.0031833679040602723,\n",
       " 'COPD': 0.002863886703383163,\n",
       " 'ASTHMA': 0.002840998497961519,\n",
       " 'INMSUPR': 0.0032463104689697923,\n",
       " 'HIPERTENSION': 0.0029602079011992466,\n",
       " 'OTHER_DISEASE': 0.0048112915146746775,\n",
       " 'CARDIOVASCULAR': 0.0029335049948739957,\n",
       " 'OBESITY': 0.0028915432849343156,\n",
       " 'RENAL_CHRONIC': 0.0028667477290608683,\n",
       " 'TOBACCO': 0.0030708342274038576,\n",
       " 'CLASIFFICATION_FINAL': 0.0,\n",
       " 'ICU': 0.8163765109791861}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for column in data.columns:    \n",
    "    # Count the occurrences of special codes (97, 98, 99) in these columns\n",
    "    to_replace = [97, 98, 99,'9999-99-99']\n",
    "    special_code_counts = {column: data[column].value_counts().loc[lambda x: x.index.isin(to_replace)]\\\n",
    "        .sum() for column in data.columns}\n",
    "    # Total count for perspective\n",
    "    total_counts = {column: data[column].count() for column in data.columns}\n",
    "    # Find total special code\n",
    "    special_code_proportions = {column: special_code_counts[column] / total_counts[column] for column in data.columns}\n",
    "special_code_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c797d8fd",
   "metadata": {},
   "source": [
    "- Next the optimum approach is to exclude the features with high missing values.\n",
    "- To perform this, it is better to do it dynamically (removing based on a filter not by manual inspection)\n",
    "- For me I have chosen the features with high missing values (More than 0.3) to be dropped (along side with the Y which is the target column) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7744e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'USMER': 0.0,\n",
       " 'MEDICAL_UNIT': 0.0,\n",
       " 'SEX': 0.0,\n",
       " 'PATIENT_TYPE': 0.0,\n",
       " 'PNEUMONIA': 0.015261664640106812,\n",
       " 'AGE': 0.0003290179529361276,\n",
       " 'DIABETES': 0.0031833679040602723,\n",
       " 'COPD': 0.002863886703383163,\n",
       " 'ASTHMA': 0.002840998497961519,\n",
       " 'INMSUPR': 0.0032463104689697923,\n",
       " 'HIPERTENSION': 0.0029602079011992466,\n",
       " 'OTHER_DISEASE': 0.0048112915146746775,\n",
       " 'CARDIOVASCULAR': 0.0029335049948739957,\n",
       " 'OBESITY': 0.0028915432849343156,\n",
       " 'RENAL_CHRONIC': 0.0028667477290608683,\n",
       " 'TOBACCO': 0.0030708342274038576}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_filtered_features = {k: v for k, v in special_code_proportions.items() if v <= 0.3 and k not in ['CLASIFFICATION_FINAL']}\n",
    "dynamic_filtered_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a242f",
   "metadata": {},
   "source": [
    "- The Classification final should be encoded to either 0 or 1 by checking the description you will find that:\n",
    "    - People with 0 to 3 are diagnosed as covid-19\n",
    "    - People with 4 or more are not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d7f9adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASIFFICATION_FINAL\n",
       "7    499250\n",
       "3    381527\n",
       "6    128133\n",
       "5     26091\n",
       "1      8601\n",
       "4      3122\n",
       "2      1851\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['CLASIFFICATION_FINAL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a00b79f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping them into Positive and Negative.\n",
    "data['CLASIFFICATION_FINAL'] = data['CLASIFFICATION_FINAL'].map({1: 'POS', 2: 'POS', 3: 'POS', 4:'NEG', 5:'NEG', 6:'NEG', 7:'NEG'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7b9567f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Metwalli\\AppData\\Local\\Temp\\ipykernel_13540\\3399123075.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mask['CLASIFFICATION_FINAL'] = data['CLASIFFICATION_FINAL'] # Add the target column back\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1024460, 17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update feature selection based on the analysis above\n",
    "updated_features = list(dynamic_filtered_features.keys())\n",
    "mask = data[updated_features] # Select only the updated features from the dataset\n",
    "mask['CLASIFFICATION_FINAL'] = data['CLASIFFICATION_FINAL'] # Add the target column back\n",
    "for column in mask.columns:\n",
    "    if column != 'CLASIFFICATION_FINAL':\n",
    "        mask = mask[(mask[column]<96)] # Excluding the 97,98,99 missing data from data\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eecb2f",
   "metadata": {},
   "source": [
    "### Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f057c83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Update feature selection based on the analysis above\n",
    "X_updated = mask.drop('CLASIFFICATION_FINAL',axis=1)\n",
    "Y = mask['CLASIFFICATION_FINAL']\n",
    "# Split the updated dataset into training and testing sets\n",
    "X_train_updated, X_test_updated, Y_train, Y_test = train_test_split(X_updated, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0151fe",
   "metadata": {},
   "source": [
    "#### Normalization using Z-score & Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8374bd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform it\n",
    "X_train_updated = scaler.fit_transform(X_train_updated)\n",
    "\n",
    "# Apply the same transformation to the test data\n",
    "X_test_updated = scaler.transform(X_test_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b8a964",
   "metadata": {},
   "source": [
    "#### Cross Validation (KEEP THIS STEP ASIDE FOR A WHILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43cf2c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import KFold, cross_val_score\n",
    "# # Initialize the logistic regression model\n",
    "# model_updated = LogisticRegression(n_jobs=-1)\n",
    "\n",
    "# # Define K-Fold cross-validation\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# # Perform K-Fold CV to evaluate model\n",
    "# scores = cross_val_score(model_updated, X_train_updated, Y_train, cv=kf, scoring='accuracy')\n",
    "# print(f'Cross-Validation Accuracy Scores: {scores}')\n",
    "# print(f'Mean CV Accuracy: {scores.mean()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7881b5b0",
   "metadata": {},
   "source": [
    "# Data Preprocessing: Regularization\n",
    "\n",
    "- Regularization is a technique used in machine learning and statistics to prevent overfitting by penalizing large coefficients in a model. \n",
    "- Overfitting occurs when a model learns noise with data that negatively impacts the performance of the model on new data.\n",
    "- Regularization techniques add a penalty on the size of the coefficients to the loss function. \n",
    "- Common types of regularization include L1 regularization (Lasso), L2 regularization (Ridge), and Elastic Net (Hybrid)\n",
    "\n",
    "## Mathematical Background\n",
    "\n",
    "Regularization is is achieved by adding a penalty term to the loss function, which discourages overly complex models by penalizing large coefficients. The general form of a regularized loss function is:\n",
    "\n",
    "$$ \\text{Loss}_{\\text{regularized}} = \\text{Loss}_{\\text{original}} + \\lambda \\times \\text{Penalty} $$\n",
    "\n",
    "Here, $\\text{Loss}_{\\text{original}}$ represents the original loss function, such as Mean Squared Error (MSE) for regression tasks. The parameter $\\lambda \\geq 0$ is known as the regularization strength; higher values of $\\lambda$ apply a stronger penalty, thus encouraging simpler models. The $\\text{Penalty}$ term is responsible for imposing costs on the size of coefficients, and its form varies depending on the type of regularization applied.\n",
    "\n",
    "### L1 Regularization (Lasso)\n",
    "\n",
    "L1 regularization, also known as Lasso (Least Absolute Shrinkage and Selection Operator), imposes a penalty equal to the absolute value of the magnitude of coefficients. This can be mathematically represented as:\n",
    "\n",
    "$$ \\text{Penalty}_{L1} = \\sum_{i=1}^{n} |w_i| $$\n",
    "\n",
    "where $w_i$ are the model coefficients. L1 regularization tends to produce sparse models, where a subset of coefficients can become exactly zero. This property makes Lasso regularization particularly useful for feature selection in models with high-dimensional data.\n",
    "\n",
    "### L2 Regularization (Ridge)\n",
    "\n",
    "L2 regularization, known as Ridge regression, applies a penalty equal to the square of the magnitude of coefficients:\n",
    "\n",
    "$$ \\text{Penalty}_{L2} = \\sum_{i=1}^{n} w_i^2 $$\n",
    "\n",
    "This form of regularization tends to distribute the penalty among all coefficients, pushing them closer to zero but rarely to zero. Unlike L1 regularization, L2 does not naturally result in feature selection but is effective in handling multicollinearity (when independent variables are highly correlated) by distributing the coefficient values across similar features.\n",
    "\n",
    "### Key Differences between L1 and L2 Regularization\n",
    "\n",
    "The core difference between L1 and L2 regularization lies in their penalty terms and the resulting impact on the model coefficients:\n",
    "\n",
    "- **Sparsity**: L1 can zero out coefficients entirely, making it great for automatic feature selection; L2 (Ridge) shrinks all coefficients toward zero but rarely eliminates them, so it keeps every feature in the model.\n",
    "- **Path and Geometry**: The L1 penalty creates a piecewise‑linear solution path, which “jumps” coefficients to zero once λ is large enough. The L2 penalty yields a smooth, continuous path where coefficients decay gradually.\n",
    "- **Robustness and Stability**: L1’s absolute penalty is less sensitive to outliers, often yielding more robust models when data contain anomalies. L2’s squared penalty gives more numerically stable solutions, especially helpful when predictors are highly correlated.\n",
    "\n",
    "### Elastic Net\n",
    "\n",
    "Elastic Net is a hybrid regularization technique that combines the penalties of L1 and L2 regularization:\n",
    "\n",
    "$$ \\text{Penalty}_{\\text{ElasticNet}} = \\rho \\sum_{i=1}^{n} |w_i| + (1 - \\rho) \\sum_{i=1}^{n} w_i^2 $$\n",
    "\n",
    "Here, $\\rho$ is the mixing parameter that controls the balance between L1 and L2 regularization penalties. Elastic Net is particularly useful when there are multiple features correlated with each other. It combines the feature selection capability of L1 with the regularization strength of L2, making it a versatile choice for various modeling scenarios.\n",
    "\n",
    "## Selecting the Regularization Strength $\\lambda$\n",
    "\n",
    "To ensure a fair comparison between Lasso, Ridge, and Elastic Net, we construct a unified grid of $\\lambda$ values:\n",
    "\n",
    "1. **Compute the maximum $\\lambda$:**\n",
    "\n",
    "   $$\n",
    "   \\lambda_{\\max}\n",
    "   = \\frac{1}{n}\\,\\max_{j} \\bigl|\\,X_{\\!\\cdot j}^\\top y\\bigr|\n",
    "   $$\n",
    "\n",
    "   ```python\n",
    "   n = X_train_updated.shape[0]\n",
    "   lambda_max = np.abs(X_train_updated.T.dot(y)).max() / n\n",
    "   print(\"lambda_max:\", lambda_max)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde35e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_max: 0.09317532780099191\n",
      "Best l1_ratio (ρ) using ElasticNetCV: 0.90\n",
      "Best λ using ElasticNetCV: 9.317533e-03\n",
      "Train R² using ElasticNetCV: 0.0565\n",
      "ElasticNetCV kept 12 features, dropped 4\n",
      "PNEUMONIA        -0.046410\n",
      "OBESITY          -0.016818\n",
      "MEDICAL_UNIT     -0.006223\n",
      "DIABETES         -0.002833\n",
      "USMER             0.000000\n",
      "ASTHMA            0.000000\n",
      "HIPERTENSION     -0.000000\n",
      "CARDIOVASCULAR    0.000000\n",
      "RENAL_CHRONIC     0.000152\n",
      "COPD              0.001363\n",
      "OTHER_DISEASE     0.001719\n",
      "INMSUPR           0.003104\n",
      "TOBACCO           0.005029\n",
      "SEX               0.010120\n",
      "AGE               0.037831\n",
      "PATIENT_TYPE      0.038190\n",
      "dtype: float64 \n",
      "\n",
      "Best λ using LassoCV: 9.317533e-03\n",
      "Train R² using LassoCV: 0.0559\n",
      "LassoCV kept 11 features, dropped 5\n",
      "PNEUMONIA        -0.045997\n",
      "OBESITY          -0.015925\n",
      "MEDICAL_UNIT     -0.005343\n",
      "DIABETES         -0.002212\n",
      "USMER             0.000000\n",
      "ASTHMA            0.000000\n",
      "HIPERTENSION     -0.000000\n",
      "CARDIOVASCULAR    0.000000\n",
      "RENAL_CHRONIC     0.000000\n",
      "COPD              0.000292\n",
      "OTHER_DISEASE     0.000766\n",
      "INMSUPR           0.002244\n",
      "TOBACCO           0.004018\n",
      "SEX               0.009182\n",
      "AGE               0.037259\n",
      "PATIENT_TYPE      0.037917\n",
      "dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# WHY REQUIRES NORMALIZATION????????\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "\n",
    "# 1. Prepare y\n",
    "y_reg = Y_train.map({'NEG': 0, 'POS': 1}).values\n",
    "\n",
    "# 2. Scale X so all features have mean=0, std=1\n",
    "scaler    = StandardScaler()\n",
    "X_scaled  = scaler.fit_transform(X_train_updated)\n",
    "\n",
    "# 3. Compute lambda_max on the scaled data\n",
    "n = X_scaled.shape[0]\n",
    "lambda_max = np.abs(X_scaled.T.dot(y_reg)).max() / n\n",
    "print(\"lambda_max:\", lambda_max)\n",
    "\n",
    "# 4. Build a wide grid of 100 points! to encourage sparsity\n",
    "#    – from lambda_max*10 down to lambda_max*0.1\n",
    "lambdas = np.logspace(\n",
    "    np.log10(lambda_max * 10),\n",
    "    np.log10(lambda_max * 0.1),\n",
    "    100\n",
    ")\n",
    "\n",
    "def APPLY_REGULARIZATION(reg, X, y):\n",
    "    reg.fit(X, y)\n",
    "    name = reg.__class__.__name__\n",
    "\n",
    "    if hasattr(reg, 'l1_ratio_'):\n",
    "        print(f\"Best l1_ratio (ρ) using {name}: {reg.l1_ratio_:.2f}\")\n",
    "    print(f\"Best λ using {name}: {reg.alpha_:.6e}\")\n",
    "    print(f\"Train R² using {name}: {reg.score(X, y):.4f}\")\n",
    "\n",
    "    coef = pd.Series(reg.coef_, index=X_updated.columns)\n",
    "    print(f\"{name} kept {(coef!=0).sum()} features, dropped {(coef==0).sum()}\")\n",
    "    print(coef.sort_values(), \"\\n\")\n",
    "\n",
    "# 5. Run pure ElasticNetCV (tuning λ & ρ) on scaled X\n",
    "APPLY_REGULARIZATION(\n",
    "    ElasticNetCV(\n",
    "        alphas=lambdas,\n",
    "        l1_ratio=[0.9],\n",
    "        cv=5,\n",
    "        max_iter=5000\n",
    "    ),\n",
    "    X_scaled, y_reg\n",
    ")\n",
    "\n",
    "# 6. Run pure LassoCV on scaled X\n",
    "APPLY_REGULARIZATION(\n",
    "    LassoCV(\n",
    "        alphas=lambdas,\n",
    "        cv=5,\n",
    "        max_iter=5000\n",
    "    ),\n",
    "    X_scaled, y_reg\n",
    ")\n",
    "\n",
    "APPLY_REGULARIZATION(\n",
    "    RidgeCV(\n",
    "        alphas=lambdas,\n",
    "        cv=5,\n",
    "        max_iter = 5000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607a19ce",
   "metadata": {},
   "source": [
    "# BONUS? Apply Regularization/CV within the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4595ed98",
   "metadata": {},
   "source": [
    "## Logistic Loss with Regularization\n",
    "\n",
    "The penalized logistic loss you’re minimizing is\n",
    "\n",
    "$$\n",
    "L(w)\n",
    "= -\\frac{1}{n}\\sum_{i=1}^n \\Bigl[y_i\\log p_i \\;+\\;(1-y_i)\\log(1-p_i)\\Bigr]\n",
    "\\;+\\;\\lambda\\,P(w),\n",
    "$$\n",
    "\n",
    "- P(w) is penalty!\n",
    "\n",
    "In scikit-learn, you supply instead the inverse regularization strength \\(C\\), with  \n",
    "\n",
    "$$\n",
    "\\lambda = \\frac{1}{C},\n",
    "$$\n",
    "\n",
    "so that **smaller** \\(C\\) ⇒ **larger** \\(\\lambda\\) (stronger regularization), and vice versa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "936b6099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best l1_ratio (ρ):   0.90\n",
      "Best C (1/λ):        1.073245e-04\n",
      "Train accuracy:      0.6562\n",
      "Kept 9 features, dropped 7\n",
      "PNEUMONIA        -0.186131\n",
      "OBESITY          -0.065277\n",
      "MEDICAL_UNIT     -0.020056\n",
      "DIABETES         -0.006808\n",
      "USMER             0.000000\n",
      "COPD              0.000000\n",
      "ASTHMA            0.000000\n",
      "HIPERTENSION      0.000000\n",
      "OTHER_DISEASE     0.000000\n",
      "CARDIOVASCULAR    0.000000\n",
      "RENAL_CHRONIC     0.000000\n",
      "INMSUPR           0.005355\n",
      "TOBACCO           0.012965\n",
      "SEX               0.036276\n",
      "PATIENT_TYPE      0.155703\n",
      "AGE               0.160196\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model  import LogisticRegressionCV\n",
    "from sklearn.metrics       import accuracy_score, roc_auc_score\n",
    "\n",
    "# 1. Prepare y\n",
    "y_cls = Y_train.map({'NEG': 0, 'POS': 1}).values\n",
    "\n",
    "# 2. Scale X once\n",
    "scaler   = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train_updated)\n",
    "\n",
    "# 3. Build a C-grid that goes *much* smaller → stronger penalty\n",
    "#    C = 1/λ, so lower C means higher λ\n",
    "#    Here we span from λ_max*1e2 → λ_max*1e-4  ⇒  C from 1e-4/λ_max → 1e2/λ_max\n",
    "n          = X_scaled.shape[0]\n",
    "lambda_max = np.abs(X_scaled.T.dot(y_cls)).max() / n\n",
    "\n",
    "# allow C down!!\n",
    "Cs = np.logspace(\n",
    "    np.log10(1e-6 / lambda_max),\n",
    "    np.log10(1e-5 / lambda_max),\n",
    "    30\n",
    ")\n",
    "\n",
    "\n",
    "# 4. Fit LogisticRegressionCV with a heavy L1-mix\n",
    "logcv = LogisticRegressionCV(\n",
    "    Cs         = Cs, # default from e-4 to e4\n",
    "    penalty    = 'elasticnet',\n",
    "    solver     = 'saga',\n",
    "    l1_ratios  = [0.9],  # include pure Lasso\n",
    "    cv         = 3,\n",
    "    scoring    = 'neg_log_loss', # or accuracy (classification metrics)\n",
    "    max_iter   = 1000,\n",
    "    n_jobs     = -1,\n",
    "    refit      = True\n",
    ")\n",
    "logcv.fit(X_scaled, y_cls)\n",
    "\n",
    "# 5. Eval & inspect sparsity\n",
    "preds   = logcv.predict(X_scaled)\n",
    "#probs   = logcv.predict_proba(X_scaled)[:,1]\n",
    "acc     = accuracy_score(y_cls, preds)\n",
    "#roc_auc = roc_auc_score(y_cls, probs) # KEEP THIS FOR NOW WE SPEACK ABOUT LATER\n",
    "\n",
    "print(f\"Best l1_ratio (ρ):   {logcv.l1_ratio_[0]:.2f}\")\n",
    "print(f\"Best C (1/λ):        {logcv.C_[0]:.6e}\")\n",
    "print(f\"Train accuracy:      {acc:.4f}\")\n",
    "#rint(f\"Train ROC AUC:       {roc_auc:.4f}\") # KEEP THIS NOW WE SPEAK ABOUT IT LATER\n",
    "\n",
    "coefs = pd.Series(logcv.coef_.ravel(), index=X_updated.columns)\n",
    "print(f\"Kept { (coefs!=0).sum() } features, dropped { (coefs==0).sum() }\")\n",
    "print(coefs.sort_values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae050bd3",
   "metadata": {},
   "source": [
    "- Perfect after tweaking Cs several times and adding stronger penalties, we reduced the amount of features (7 features are dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179033c4",
   "metadata": {},
   "source": [
    "- IMPORTANT NOTE: Train accuracy 0.6562 (vs. 0.6599 before)\n",
    "You lose only about 0.3 pp of accuracy by pruning almost half your features—often a worthwhile trade-off for interpretability and simpler models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71044077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mitocluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
